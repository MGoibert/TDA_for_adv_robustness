{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tda.experiments.ocsvm_detector.ocsvm_detector_binary import *\n",
    "from tda.embeddings import EmbeddingType, KernelType\n",
    "from tda.models.architectures import mnist_lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    embedding_type=EmbeddingType.PersistentDiagram,\n",
    "    kernel_type=KernelType.SlicedWasserstein,\n",
    "    thresholds='0.9',\n",
    "    epochs=50,\n",
    "    dataset=\"MNIST\",\n",
    "    architecture=mnist_lenet.name,\n",
    "    train_noise=0.0,\n",
    "    dataset_size=10,\n",
    "    successful_adv=1,\n",
    "    attack_type=\"FGSM\",\n",
    "    identical_train_samples=1,\n",
    "    noise=0.0,\n",
    "    \n",
    "    num_iter=1,\n",
    "    height=1,\n",
    "    hash_size=1,\n",
    "    node_labels=0,\n",
    "    steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_train, embedding_test, adv_embeddings, thresholds, stats, stats_inf = get_all_embeddings(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Using kernel {config.kernel_type} with embeddings {config.embedding_type}\")\n",
    "\n",
    "if config.kernel_type == KernelType.RBF:\n",
    "    param_space = [\n",
    "        {'gamma': gamma}\n",
    "        for gamma in np.logspace(-6, -3, 10)\n",
    "    ]\n",
    "elif config.kernel_type == KernelType.SlicedWasserstein:\n",
    "    param_space = [\n",
    "        {'M': 20, 'sigma': 5 * 10 ** (-1)},\n",
    "    ]\n",
    "else:\n",
    "    raise NotImplementedError(f\"Unknown kernel {config.kernel_type}\")\n",
    "\n",
    "gram_train_matrices = {i: get_gram_matrix(\n",
    "    kernel_type=config.kernel_type,\n",
    "    embeddings_in=embedding_train,\n",
    "    embeddings_out=None,\n",
    "    params=param\n",
    ")\n",
    "    for i, param in enumerate(param_space)\n",
    "}\n",
    "logger.info(f\"Computed all Gram train matrices !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_results = {\n",
    "        epsilon: evaluate_embeddings(\n",
    "            gram_train_matrices=gram_train_matrices,\n",
    "            embeddings_train=embedding_train,\n",
    "            embeddings_test=embedding_test,\n",
    "            adv_embeddings=adv_embeddings[epsilon],\n",
    "            param_space=param_space,\n",
    "            kernel_type=config.kernel_type\n",
    "        )\n",
    "        for epsilon in adv_embeddings\n",
    "    }\n",
    "\n",
    "logger.info(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
